lm(y~x-1)
g
df
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()#+
#lm(y~x-1)
g
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
lm(y~x-1,data=df)
g
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x)
g
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x-1)
g
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x-1) +
xlim(0,1)
g
###Question Two
Consider the following data set
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
Fit the regression through the origin and get the slope treating y as the outcome and x as the regressor.
(Hint, do not center the data since we want regression through the origin, not through the means of the data.)
```{r Q2}
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
df<-data.frame(cbind(x,y))
lm(y~x - 1)
```
```{r plot for Q2}
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x-1) +
xlim(0,1)
g
```
mtcars
str(mtcars)
data(mtcars)
lm(mpg~weight,data=mtcars)
data(mtcars)
lm(mpg~wt,data=mtcars)
library(ggplot2)
g<-ggplot(mtcars,aes(wt=x,y=mpg))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x) +
xlim(0,max(mtcars$wt))
g
summary(mtcars)
library(ggplot2)
g<-ggplot(mtcars,aes(x=wt,y=mpg))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x) +
xlim(0,max(mtcars$wt))
g
data(mtcars)
lm(mpg~wt,data=mtcars)
library(ggplot2)
g<-ggplot(mtcars,aes(x=wt,y=mpg))+
geom_point()+
stat_smooth_func(geom="text",method="lm",hjust=0,parse=TRUE)+
#geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x) +
xlim(0,max(mtcars$wt))
g
library(ggplot2)
g<-ggplot(mtcars,aes(x=wt,y=mpg))+
geom_point()+
stat_smooth_func(geom="text",method="lm",hjust=0,parse=TRUE)+
#geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x)
# xlim(0,max(mtcars$wt))
g
library(ggplot2)
g<-ggplot(mtcars,aes(x=wt,y=mpg))+
geom_point()+
stat_smooth_func(geom="text",method="lm",hjust=0,parse=TRUE)+
#geom_smooth(method=lm,   # Add linear regression line
#se=FALSE,formula=y~x)
# xlim(0,max(mtcars$wt))
g
library(ggplot2)
g<-ggplot(mtcars,aes(x=wt,y=mpg))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x)+
xlim(0,max(mtcars$wt))
g
data(mtcars)
lm(mpg~wt,data=mtcars)
?sd
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
z<-(x-mean(x))sd(x)
z
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
z<-(x-mean(x))/sd(x)
z
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x1) +
xlim(0,1)
g
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
df<-data.frame(cbind(x,y))
lm(y~x1)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
df<-data.frame(cbind(x,y))
lm(y~x)
library(ggplot2)
g<-ggplot(df,aes(x=x,y=y))+
geom_point()+
geom_smooth(method=lm,   # Add linear regression line
se=FALSE,formula=y~x) +
xlim(0,1)
g
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
xbar<-mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
xbar<-mean(x)
xbar
library(swirl)
install.packages("swirl")
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
swirl()
dice_sqr
ex2_fair<-sum(dice_fair*dice_sqr)
ex2_fair-3.5
ex2_fair-3.5^2
sum(dice_high*dice_sqr)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1000),1,mean)
sd(apply(matrix(rpois(10000,4),1000),1000),1,mean))
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
1-25/5^5
1-21/5^5
0.43
.43008
choose(5,3)
?choose
.43008
info()
choose(5,3) * 0.8^3 * (1-0.8)^(5-3)+choose(5,4) * 0.8^4 * (1-0.8)^(5-4)+choose(5,5) * 0.8^5 * (1-0.8)^(5-5)
?pbinom
pbinom(2,5,0.8,lower.tail=FALSE)
qnorm(0.1)
0
?qnorm
qnorm(.975,3,2)
3+2*1.96
pnorm(1200,1020,50,lower.tail=FALSE)
pnorm((1200-1050)/50)
pnorm((1200-1050)/50,lower.tail=FALSE)
pnorm((1200-1020)/50,lower.tail=FALSE)
qnorm(0.75,1020,50,lower.tail=TRUE)
.53
.53
?ppois
ppois(3,10,lower.tail=TRUE)
ppois(4,10,lower.tail=TRUE)
ppois(3,10)
ppois(3,2.5*4)
pbinom(5,.01,1000)
?pbinom
pbinom(5,1000,0.01)
ppois(5,1000*0.01)
rexp(40)
hist(rexp(40))
hist(rexp(40,0.2))
mean(rexp(40,0.2))
sd(rexp(40,0.2))
sd(rexp(40,0.2))
sd(rexp(40,0.2))
sd(rexp(40,0.2))
sd(rexp(40,0.2))
?matrix
dat<-matrix(rexp(40000,0.2),1000,40)
str(dat)
means<-apply(dat,1,mean)
str(means)
mean(means)
lambda<-0.2
means<-apply(matrix(rexp(40000,lambda),1000, 40), 1, mean)
str(means)
lambda<-0.2
means<-apply(matrix(rexp(40000,lambda),1000, 40), 1, mean)
hist(means)
mean(means)
sd(means)
sd(means*sqrt(40))
data(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y~x)
fit
library(ggplot2)
g<-ggplot(data=mtcars,aes(x=wt,y=mpg))
g<-g+geom_line()
g
g<-ggplot(data=mtcars,aes(x=wt,y=mpg))
g<-g+geom_point()
g
g<-g+geom_point(shape=1)
g
g<-g+geom_point(shape=1)
library(ggplot2)
g<-ggplot(data=mtcars,aes(x=wt,y=mpg))
g<-g+geom_point(shape=1)
g
source('~/.active-rstudio-document', echo=TRUE)
g+geom_point(shape=1)+
library(ggplot2)
g<-ggplot(data=mtcars,aes(x=wt,y=mpg))+
g+geom_point(shape=1)+
geom_smooth(method=lm)
g
library(ggplot2)
g<-ggplot(data=mtcars,aes(x=wt,y=mpg))+
geom_point(shape=1)+
geom_smooth(method=lm)
g
library(ggplot2)
g<-ggplot(data=mtcars,aes(x=wt,y=mpg))+
geom_point(shape=1)+
geom_smooth(method=lm)
g
meanx<-mean(x)
meanx
meany<-mean(y)
meany
summary(mtcars)
head(mtcars)
?mtcars
summary(lm)
summary(fit)
length(x)
sd(y)
mean(y)
data(mtcars)
library(mtcars)
str(mtcars)
fit<-lm(mpg~factor(cyl)+wt,data=mtcars)
summary(fit)
fit<-lm(mpg~factor(cyl)+wt,data=mtcars)
summary(fit)
fitnf<-lm(mpg~cyl+wt,data=mtcars)
summary(fitnf)
fitnf<-lm(mpg~cyl+wt,data=mtcars)
fit<-lm(mpg~factor(cyl)+wt,data=mtcars)
summary(fit)
fitnf<-lm(mpg~cyl+wt,data=mtcars)
summary(fitnf)
# This time we'll generate the necessary fake data
# within R itself, rather than working in Python and
# then reading the data into R.  This will demonstrate
# some handy R commands that you may not have known about.
# Let's start with a problem where the predictor variable X
# does not seem to have a linear relationship with Y and
# needs to be transformed
rawx = runif(200,min=0,max=10)
X = exp(rawx)
ydev = rnorm(200,0,1)
Y = rawx + ydev
png("plotOfYonX.png")
plot (X,Y,col="red",pch=16)
title(main="A plot of Y on X")
graphics.off()
# Now try transforming the X variable using the natural
# log function
logX = log(X)
png("plotOfYonLogX.png")
plot (logX,Y,col="red",pch=16)
title(main="A plot of Y on log(X)")
graphics.off()
# Note the correlations between Y and each version of X
cor(X,Y)
cor(logX,Y)
# Another problem where the predictor variable X
# does not seem to have a linear relationship with Y and
# needs to be transformed (x^2 this time)
rawx = runif(200,min=0,max=80)
rawx = sort(rawx)
X = sqrt(rawx)
ydev = rnorm(200,0,2)
Y = rawx + ydev
png("plotOfYonX2.png")
plot (X,Y,col="red",pch=16)
title(main="A plot of Y on X")
graphics.off()
expX = exp(X)
X2 = X * X
png("plotOfYonExpX.png")
plot (expX,Y,col="red",pch=16)
title(main="A plot of Y on exp(X)")
graphics.off()
png("plotOfYonXSquared.png")
plot (X2,Y,col="red",pch=16)
title(main="A plot of Y on X-squared")
graphics.off()
# Fit linear models to the raw X and the two transformations
unchanged = lm (Y ~ X)
expTrans = lm ( Y ~ expX )
squareTrans = lm ( Y ~ X2 )
# Use AIC to choose between the three models
AIC (unchanged,expTrans,squareTrans)
# Plot the predictions from the three models all on one plot
png("plotOfModelFits.png")
plot (X,Y,col="red",pch=16)
lines(X,predict(unchanged),col="blue",lw=2)
lines(X,predict(expTrans),col="green",lw=2)
lines(X,predict(squareTrans),col="black",lw=2)
title(main="Various models for Y")
graphics.off()
# Now a problem where there's a polynomial relationship between
# X and Y.
X = runif(200,min=-10,max=10)
X = sort(X)
ydev = rnorm(200,0,4)
Y = 62.3 + 0.4 * X - 0.2 * X^2 + 0.03 * X^3 + ydev
png("plotOfYonPolyX.png")
plot (X,Y,col="red",pch=16)
title(main="A plot of Y on X")
graphics.off()
# We fit the null, the linear, and some polynomial models of
# increasing degree.  In fact the right answer is the 3rd order
# polynomial model (look how we created the data above) and
# the AIC method identifies this model.
m0 = lm ( Y ~ 1 )
m1 = lm ( Y ~ X )
m2 = lm ( Y ~ X + I(X^2) )
m3 = lm ( Y ~ X + I(X^2) + I(X^3) )
m4 = lm ( Y ~ X + I(X^2) + I(X^3) + I(X^4) )
AIC(m0,m1,m2,m3,m4)
# Produce a plot of the different polynomial models
# fitted to the data
png("plotOfPolyModelFits.png",width=600,height=600)
plot (X,Y,col="red",pch=16)
lines(X,predict(m0),col="grey",lw=2)
lines(X,predict(m1),col="green",lw=2)
lines(X,predict(m2),col="yellow",lw=2)
lines(X,predict(m2),col="blue",lw=2)
lines(X,predict(m3),col="black",lw=2)
title(main="Various polynomial models for Y")
graphics.off()
# Now investigate a situation where there is a significant
# interaction term
X = runif(200,min=0,max=20)
X = sort(X)
GroupChoice = runif(200)
Group = ifelse(GroupChoice < 0.5, "A", "B")
Y = ifelse(GroupChoice < 0.5, 36 + X*4.2, 100 - X*2)
colour = ifelse(GroupChoice < 0.5, "red", "blue")
ydev = rnorm(200,0,12)
Y = Y + ydev
# Plot the relationship between X and Y
png("plotOfYInteractionAllSame.png")
plot (X,Y,col="red",pch=16)
title(main="A plot of Y on X")
graphics.off()
# Plot the relationship between X and Y, highlighting
# the effects of Group
png("plotOfYInteraction.png")
plot (X,Y,col=colour,pch=16)
title(main="A plot of Y on X")
graphics.off()
# Now fit a regression model of Y on X and Group
# Use the drop1 command to see if the interaction term can go
Group = as.factor(Group)
fullModel = lm ( Y ~ X*Group)
summary(fullModel)
drop1(fullModel)
# Plot the relationship between X and Y, highlighting
# the effects of Group, and showing the fitted model
png("plotOfYInteractionFitted.png",width=600,height=600)
plot (X,Y,col=colour,pch=16)
points(X,predict(fullModel),col="green",pch=15)
title(main="A plot of Y on X, with fitted interaction model")
graphics.off()
getwd()
setwd("H:/Rspace/JHU_Data_Science/JHU_RM")
fitcf<-lm(mpg~factor(cyl)+wt)
fitint<-lm(mpg~factor(cyl)*wt)
summary(fitcf)
summary(fitint)
fitcf<-lm(mpg~factor(cyl)+wt,data=mtcars)
fitint<-lm(mpg~factor(cyl)*wt,data=mtcars)
summary(fitcf)
summary(fitint)
InsectSprays
library(dplyr)
summarise(group_by(InsectSprays, spray), mn = mean(count))
fitcf<-lm(mpg~factor(cyl)+wt,data=mtcars)
fitint<-lm(mpg~factor(cyl)*wt,data=mtcars)
summary(fitcf)
summary(fitint)
fit4<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4
fit4<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4
fit4nf<-lm(mpg ~ I(wt * 1) + factor(cyl), data = mtcars)
fit4nf
swirl()
library(swirl)
rm(list=ls())
swirl()
install_from_swirl("Regression Models")
swirl()
fit<-lm(y~x,out2)
play()
?plot
nxt()
plot(fit,which=1)
fitno<-lm(x~y,data=out2[-1,])
fitno<-lm(x~y,out2[-1,])
fitno<-lm(y~x,out2[-1,])
plot(fitno,which=1)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma<-sqrt(deviance(fit)/()
sigma<-sqrt(deviance(fit)/(nrow(fit)-1))
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd<-resid(fit)/(sigma*sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1<-sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/sigma1*sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy<-predict(fitno, out2)-predict(fit, out2)
dy/(2*sigma^2)
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-cbind(x,)
fit5<-lm(y~x,data=df)
summary(fit5)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-cbind(x,y)
fit5<-lm(y~x,data=df)
summary(fit5)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
fit5<-lm(y~x,data=df)
summary(fit5)
?hatvalues
hatvalues(fit5)
?dfbeta
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
dfbeta(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
dfbeta(df
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
dfbeta(df)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
fit6<-lm(y~x,data=df)
dfbeta(fit6)
plot(x,y)
dfbeta(df)
dfbeta(fit,data=df[-5,])
dfbeta(fit[-5,])
fit
dfbeta(fit6[-5,])
fit6
?dfbeta
dfbetas(fit6)
