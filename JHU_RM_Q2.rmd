---
title: "JHU_RM_Quiz2"
author: "mbh038"
date: "Monday, June 08, 2015"
output: html_document
---

##Question One

Consider the following data with x as the predictor and y as as the outcome.

x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
Give a P-value for the two sided hypothesis test of whether ??1 from a linear regression model is 0 or not.

2.325
0.391
__0.05296__
0.025

```{r q1}
# find this manually 

x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)

n<-length(y)

beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(y)-beta1*mean(x)

# residuals
e<-y-beta0-beta1*x

# sd around the regression line
sigma<-sqrt(sum(e^2)/(n-2))
sigma

# sums of x differences squared
ssx=sum((x-mean(x))^2)

#find errors
seBeta0<-(1/n+mean(x)^2/ssx)^.5*sigma
seBeta1<-sigma/sqrt(ssx)

#find t values
tBeta0<-beta0/seBeta0
tBeta1<-beta1/seBeta1

pBeta0<-2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)
pBeta1<-2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)

# coefficient table
coefTable<-rbind(c(beta0,seBeta0,tBeta0,pBeta0),
                 c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable)<-c("Estimate","Std. Error","t value","P(>|t|)")
rownames(coefTable)<-c("(Intercept)","x")
coefTable

```
Now do this using the lm function
```{r q1 lm fit}
fit<-lm(y~x)
summary(fit)$coefficients

##q1 find confidence interval
sumCoef<-summary(fit)$coefficients
sumCoef[1,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
```

##Question Three

```{r q3}
rm(list=ls())
data(mtcars)
x<-mtcars$wt
y<-mtcars$mpg

n<-length(y)

beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(y)-beta1*mean(x)

# residuals
e<-y-beta0-beta1*x

# sd around the regression line
sigma<-sqrt(sum(e^2)/(n-2))
sigma


fit<-lm(y~x)
summary(fit)$coefficients

sumCoef<-summary(fit)$coefficients
beta0Range<-sumCoef[1,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
beta0Range
beta1Range<-sumCoef[2,1]+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
beta1Range

mpgrange<-mean(y)+c(-1,1)*qt(0.975,df=fit$df)*sigma/sqrt(n)
mpgrange

library(ggplot2)

g<-ggplot(data=mtcars,aes(x=x,y=y))+
        ggtitle("Question Three") +
        geom_point(size=3,shape=1,col="red")+
        geom_smooth(method=lm)+
        geom_segment(aes(x = mean(wt), y = 0, xend = mean(wt), 
                         yend = mean(mpg)))+
        geom_segment(aes(x = min(wt), y = mean(mpg), xend = mean(wt), 
                         yend = mean(mpg)))
        #geom_line(stat="vline", xintercept="mean")+
        #geom_line(stat="hline", yintercept="mean")
g

```

##Question Five
Consider again the mtcars data set and a linear regression model with mpg as predicted by weight (1,000 lbs). A new car is coming weighing 3000 pounds. Construct a 95% prediction interval for its mpg. What is the upper endpoint?

14.93
21.25
-5.77
__27.57__

```{r q5}

#do a linear fit to the data
fit.lm = lm(mpg ~ wt,data=mtcars)

# Predict these data for...
predx <- data.frame(wt = seq(from = min(mtcars$wt), to = max(mtcars$wt), by = 0.1))

# ... prediction interval
pred.int <- cbind(predx, predict(fit.lm, newdata = predx, interval = "prediction", level = 0.95))

# ''' confidence interval
conf.int <- cbind(predx, predict(fit.lm, newdata = predx, interval = "confidence", level = 0.95))

g<- ggplot(pred.int, aes(x = wt, y = fit)) +
  theme_bw() +
  ggtitle("Question Five- Prediction interval and Confidence interval") +
  geom_point(data = mtcars, aes(x = wt, y = mpg)) +
  geom_smooth(data = pred.int, aes(ymin = lwr, ymax = upr), stat = "identity")+
  geom_smooth(data = conf.int, aes(ymin = lwr, ymax = upr), stat = "identity")
g

#find width of 95% prediction interval at wt=3
newdata = data.frame(wt=3)
predict(fit.lm, newdata, interval="prediction",level=0.95) 
```

##Question Six

Consider again the mtcars data set and a linear regression model with mpg as
predicted by weight (in 1,000 lbs). A "short" ton is defined as 2,000 lbs.
Construct a 95% confidence interval for the expected change in mpg per 1 short
ton increase in weight. Give the lower endpoint.

__-12.973__
-9.000
-6.486
4.2026

```{r q6}
delta<-2*(beta1+c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])
delta
```

##Question Eight
```{r q8}
c<-2
xc<-x+c
fitc<-lm(y~xc)
fit$coefficients[[1]]-fitc$coefficients[[1]]
```

##Question Nine

```{r q9}
# residuals^2 - the numerator
num<-sum((y-beta0-beta1*x)^2)
# differences from mean^2 - denominator
den<-sum((y-mean(y))^2)
num/den
```

